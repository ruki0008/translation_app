import 'dart:async';
import 'dart:io';
import 'package:flutter/material.dart';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import 'package:cloud_firestore/cloud_firestore.dart';

import 'api_service.dart';
import 'custom_words_edit_screen.dart';

class WhisperTranslatePage extends StatefulWidget {
  const WhisperTranslatePage({super.key});

  @override
  State<WhisperTranslatePage> createState() => _WhisperTranslatePage();
}

class _WhisperTranslatePage extends State<WhisperTranslatePage> {
  final AudioRecorder _recorder = AudioRecorder();
  final ApiService _apiService = ApiService();

  bool _isRecording = false;
  bool _isProcessing = false;

  String? _audioPath;
  final StringBuffer _resultBuffer = StringBuffer();

  Timer? _silenceTimer;
  Timer? _amplitudeTimer;

  static const double silenceThreshold = -40.0;
  static const Duration silenceDuration = Duration(seconds: 2);

  /// å›ºæœ‰åè©å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
  final TextEditingController _promptController = TextEditingController();

  /// Firestore ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
  final promptsRef = FirebaseFirestore.instance.collection("prompts");

  @override
  void dispose() {
    _amplitudeTimer?.cancel();
    _silenceTimer?.cancel();
    _recorder.dispose();
    _promptController.dispose();
    super.dispose();
  }

  // ======================================================
  // ğŸ”¹ å›ºæœ‰åè©ã‚’ Firestore ã«ä¿å­˜
  // ======================================================
  Future<void> _savePromptWord() async {
    final text = _promptController.text.trim();
    if (text.isEmpty) return;

    await promptsRef.add({
      "word": text,
      "createdAt": DateTime.now(),
    });

    _promptController.clear();

    ScaffoldMessenger.of(context).showSnackBar(
      const SnackBar(content: Text("å›ºæœ‰åè©ã‚’ä¿å­˜ã—ã¾ã—ãŸ")),
    );
  }

  // ======================================================
  // ğŸ”¹ Firestore ã®å˜èªã‚’ Whisper ã«æ¸¡ã™ãŸã‚å–å¾—
  // ======================================================
  Future<String> _loadPromptWords() async {
    final snap = await promptsRef.get();
    final words = snap.docs.map((d) => d["word"]).join(", ");
    return words;
  }

  // ======================================================
  // ğŸ”¹ éŒ²éŸ³é–‹å§‹
  // ======================================================
  Future<void> _startRecording() async {
    if (!await _recorder.hasPermission()) return;

    final dir = await getTemporaryDirectory();
    _audioPath = "${dir.path}/record_0.m4a";

    await _recorder.start(
      const RecordConfig(encoder: AudioEncoder.aacLc),
      path: _audioPath!,
    );

    _startAmplitudeMonitoring();

    setState(() => _isRecording = true);
  }

  // ======================================================
  // ğŸ”¹ ç„¡éŸ³æ¤œçŸ¥ã§ãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²
  // ======================================================
  void _startAmplitudeMonitoring() {
    int fileIndex = 1;

    _amplitudeTimer?.cancel();
    _amplitudeTimer = Timer.periodic(
      const Duration(milliseconds: 200),
      (_) async {
        final amp = await _recorder.getAmplitude();
        final db = amp.current;

        if (db < silenceThreshold) {
          _silenceTimer ??= Timer(silenceDuration, () async {
            if (!_isRecording) return;

            final dir = await getTemporaryDirectory();
            final newPath = "${dir.path}/record_$fileIndex.m4a";
            fileIndex++;

            await _recorder.stop();
            await _recorder.start(
              const RecordConfig(encoder: AudioEncoder.aacLc),
              path: newPath,
            );

            final oldFile =
                File("${dir.path}/record_${fileIndex - 2}.m4a");

            _audioPath = newPath;

            if (oldFile.existsSync() && oldFile.lengthSync() > 1000) {
              _sendFileForTranscription(oldFile);
            }
          });
        } else {
          _silenceTimer?.cancel();
          _silenceTimer = null;
        }
      },
    );
  }

  // ======================================================
  // ğŸ”¹ éŒ²éŸ³åœæ­¢
  // ======================================================
  Future<void> _stopRecording() async {
    if (!_isRecording) return;

    _amplitudeTimer?.cancel();
    _silenceTimer?.cancel();

    await _recorder.stop();

    setState(() {
      _isRecording = false;
      _isProcessing = true;
    });

    if (_audioPath != null &&
        File(_audioPath!).existsSync() &&
        File(_audioPath!).lengthSync() > 1000) {
      await _sendFileForTranscription(File(_audioPath!));
    }

    setState(() => _isProcessing = false);
  }

  // ======================================================
  // ğŸ”¹ Whisper ã¸é€ä¿¡
  //    Firestoreã®å›ºæœ‰åè©ã‚’ä¸€ç·’ã«æ¸¡ã™
  // ======================================================
  Future<void> _sendFileForTranscription(File file) async {
    final promptWords = await _loadPromptWords();

    final result = await _apiService.transcribeAndTranslate(
      file.path,
      prompt: promptWords, // â† â˜… è¿½åŠ 
    );

    if (!mounted) return;

    if (result != null) {
      _resultBuffer.writeln("æ–‡å­—èµ·ã“ã—: ${result['text']}");
      _resultBuffer.writeln("ç¿»è¨³çµæœ: ${result['translation']}\n");
    } else {
      _resultBuffer.writeln("æ–‡å­—èµ·ã“ã—/ç¿»è¨³ã«å¤±æ•—ã—ã¾ã—ãŸ\n");
    }

    setState(() {});
  }

  // ======================================================
  // ğŸ”¹ UI
  // ======================================================
  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: const Text("éŸ³å£°æ–‡å­—èµ·ã“ã—")),
      body: Padding(
        padding: const EdgeInsets.all(16),
        child: Column(
          children: [
            Expanded(
              child: SingleChildScrollView(
                child: Text(
                  _resultBuffer.toString(),
                  style: const TextStyle(fontSize: 18),
                ),
              ),
            ),

            const SizedBox(height: 12),

            ElevatedButton(
              onPressed: () {
                Navigator.push(
                  context,
                  MaterialPageRoute(
                      builder: (_) => const CustomWordsEditPage()),
                );
              },
              child: const Text("å›ºæœ‰åè©ã‚’ç™»éŒ²ãƒ»ç·¨é›†ï¼ˆæœ€å¤§20ä»¶ï¼‰"),
            ),

            const SizedBox(height: 16),

            // éŒ²éŸ³ãƒœã‚¿ãƒ³
            ElevatedButton.icon(
              icon: Icon(_isRecording ? Icons.stop : Icons.mic),
              label: Text(
                _isRecording
                    ? "åœæ­¢"
                    : _isProcessing
                        ? "å‡¦ç†ä¸­..."
                        : "éŒ²éŸ³é–‹å§‹",
              ),
              style: ElevatedButton.styleFrom(
                backgroundColor:
                    _isRecording ? Colors.red : Colors.blue,
                minimumSize: const Size(double.infinity, 50),
              ),
              onPressed: _isProcessing
                  ? null
                  : _isRecording
                      ? _stopRecording
                      : _startRecording,
            ),
          ],
        ),
      ),
    );
  }
}